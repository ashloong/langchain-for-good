{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Environment setup and local dependencies\n",
    "We install from local `requirements.txt`, load `.env` if present, and ensure the project path is importable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and dependencies\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(r\"C:\\Users\\carry\\OneDrive\\Документы\\Cursor\\LangChain\\hna\")\n",
    "requirements_path = project_root / \"requirements.txt\"\n",
    "\n",
    "if requirements_path.exists():\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(requirements_path)])\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "for env_candidate in [project_root / \".env\", Path.cwd() / \".env\"]:\n",
    "    if env_candidate.exists():\n",
    "        load_dotenv(str(env_candidate))\n",
    "        break\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Centralized prompts (system and human)\n",
    "We keep prompts versioned and easily extendable. Adjust these variables as the scope grows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts (modifiable)\n",
    "from datetime import datetime\n",
    "\n",
    "DISCLAIMER_TEXT = (\n",
    "    \"This conversation is for education only and is not medical advice. \"\n",
    "    \"If you have urgent symptoms, seek professional care or emergency services.\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are a compassionate multi-turn health navigator.\n",
    "- Greet empathetically and acknowledge feelings.\n",
    "- Ask concise follow-ups to gather symptoms, onset, severity, and risk factors.\n",
    "- Use retrieved WHO/CDC guidance for education only.\n",
    "- Never provide diagnosis or treatment instructions.\n",
    "- Always respect the user's autonomy and privacy.\n",
    "- When flagged, prepend the disclaimer:\n",
    "  \"{DISCLAIMER_TEXT}\"\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_TEMPLATE = (\n",
    "    \"User message: {{user_input}}\\n\"\n",
    "    \"Known symptoms so far: {{symptom_state}}\\n\"\n",
    "    \"Retrieved guidance (if any): {{retrieved_context}}\\n\"\n",
    "    \"Respond empathetically and continue the dialogue.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts loaded. You can edit SYSTEM_PROMPT and HUMAN_PROMPT_TEMPLATE above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Load WHO/CDC guidance (web scraping)\n",
    "We fetch content from `https://www.who.int/health-topics` and `https://www.cdc.gov/health-topics.html` and parse text for RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHO text length: 8199\n",
      "CDC text length: 506\n"
     ]
    }
   ],
   "source": [
    "# Simple web scraper for WHO/CDC health topics\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WHO_URL = \"https://www.who.int/health-topics\"\n",
    "CDC_URL = \"https://www.cdc.gov/health-topics.html\"\n",
    "\n",
    "\n",
    "def fetch_text_from_url(url: str) -> str:\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "        # Keep visible text within main content areas; fallback to body text\n",
    "        main = soup.find(\"main\") or soup\n",
    "        texts = [t.get_text(\" \", strip=True) for t in main.find_all([\"p\", \"li\", \"h1\", \"h2\", \"h3\"])[:2000]]\n",
    "        return \"\\n\".join(t for t in texts if t)\n",
    "    except Exception as e:\n",
    "        return f\"ERROR fetching {url}: {e}\"\n",
    "\n",
    "who_text = fetch_text_from_url(WHO_URL)\n",
    "cdc_text = fetch_text_from_url(CDC_URL)\n",
    "\n",
    "print(\"WHO text length:\", len(who_text))\n",
    "print(\"CDC text length:\", len(cdc_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search JSON URL for providers by list of target zips within X mile radius of current zipcode and returns top 10 providers\n",
    "### fetch JSON url from list of providers by state: https://www22.anthem.com/cms-data-index.json/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zip codes within 10 miles of 95008:\n",
      "  95008: 0.00 miles\n",
      "  95009: 0.73 miles\n",
      "  95011: 0.73 miles\n",
      "  95130: 1.24 miles\n",
      "  95124: 2.37 miles\n",
      "  95117: 2.38 miles\n",
      "  95128: 2.80 miles\n",
      "  95129: 3.19 miles\n",
      "  95125: 3.62 miles\n",
      "  95071: 3.74 miles\n",
      "  95031: 3.75 miles\n",
      "  95126: 3.87 miles\n",
      "  95118: 4.04 miles\n",
      "  95030: 4.06 miles\n",
      "  95032: 4.42 miles\n",
      "  95053: 4.97 miles\n",
      "  95050: 5.01 miles\n",
      "  95052: 5.06 miles\n",
      "  95055: 5.06 miles\n",
      "  95056: 5.06 miles\n",
      "\n",
      "Total: 75 zip codes found\n",
      "\n",
      "Found 1358 providers in the target ZIP codes.\n",
      "\n",
      "{\n",
      "    \"npi\": \"1003008772\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"LOUISE M BRUCE\",\n",
      "    \"address\": \"750 S BASCOM AVE STE 330\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95128\",\n",
      "    \"phone\": \"8883341000\",\n",
      "    \"specialty\": \"Nurse Practitioner\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003013715\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"ROBERTA Y WANG\",\n",
      "    \"address\": \"751 S BASCOM AVE BLDG Q FL 1\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95128\",\n",
      "    \"phone\": \"4088852100\",\n",
      "    \"specialty\": \"Physical Medicine And Rehab\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003017252\",\n",
      "    \"type\": \"FACILITY\",\n",
      "    \"name\": null,\n",
      "    \"address\": \"5150 GRAVES AVE STE 6\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95129\",\n",
      "    \"phone\": \"4083660890\",\n",
      "    \"specialty\": null\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003025586\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"KARENA C PETERSEN\",\n",
      "    \"address\": \"137 E HAMILTON AVE STE 204\",\n",
      "    \"city\": \"CAMPBELL\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95008\",\n",
      "    \"phone\": \"4087720644\",\n",
      "    \"specialty\": \"Marriage/Family Therapist\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003045683\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"KALI R TILESTON\",\n",
      "    \"address\": \"751 S BASCOM AVE # Q STE 240\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95128\",\n",
      "    \"phone\": \"4087932520\",\n",
      "    \"specialty\": \"Surgery, Orthopedic\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003059395\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"QUAZI Z AL-TARIQ\",\n",
      "    \"address\": \"225 N JACKSON AVE\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95116\",\n",
      "    \"phone\": \"4082595000\",\n",
      "    \"specialty\": \"Diagnostic Radiology\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003141102\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"KHOI D NGUYEN\",\n",
      "    \"address\": \"1693 FLANIGAN DR STE 101\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95121\",\n",
      "    \"phone\": \"4082703595\",\n",
      "    \"specialty\": \"Family Practice\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003158544\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"AMANDEEP SINGH SANDHU\",\n",
      "    \"address\": \"200 JOSE FIGUERES AVE STE 465\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95116\",\n",
      "    \"phone\": \"4087295488\",\n",
      "    \"specialty\": \"Dermatology\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003226564\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"RIPAL K SHAH\",\n",
      "    \"address\": \"2400 MOORPARK AVE FL 3 STE 316B\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95128\",\n",
      "    \"phone\": \"4088855935\",\n",
      "    \"specialty\": \"Psychiatry\"\n",
      "}\n",
      "{\n",
      "    \"npi\": \"1003824699\",\n",
      "    \"type\": \"INDIVIDUAL\",\n",
      "    \"name\": \"KOMAL J BHATT\",\n",
      "    \"address\": \"200 JOSE FIGUERES AVE STE 490\",\n",
      "    \"city\": \"SAN JOSE\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"95116\",\n",
      "    \"phone\": \"4082585083\",\n",
      "    \"specialty\": \"Internal Medicine\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from geopy.distance import geodesic\n",
    "from typing import List\n",
    "import zipcodes\n",
    "\n",
    "def get_zip_codes_within_distance(target_zip: str, radius_miles: float, debug=False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of zip codes within X miles from a target zip code.\n",
    "    Uses bounding box optimization and CA-only filtering for speed.\n",
    "    \n",
    "    Args:\n",
    "        target_zip: The target zip code (string)\n",
    "        radius_miles: Search radius in miles\n",
    "    \n",
    "    Returns:\n",
    "        List of zip codes within the specified radius\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Get target zip code info\n",
    "    target_info = zipcodes.matching(target_zip)\n",
    "    if not target_info:\n",
    "        raise ValueError(f\"Could not find zip code '{target_zip}'\")\n",
    "    \n",
    "    target_lat = float(target_info[0]['lat'])\n",
    "    target_lon = float(target_info[0]['long'])\n",
    "    target_coords = (target_lat, target_lon)\n",
    "    \n",
    "    # Calculate bounding box\n",
    "    lat_offset = radius_miles / 69\n",
    "    lon_offset = radius_miles / (69 * math.cos(math.radians(target_lat)))\n",
    "    \n",
    "    min_lat = target_lat - lat_offset\n",
    "    max_lat = target_lat + lat_offset\n",
    "    min_lon = target_lon - lon_offset\n",
    "    max_lon = target_lon + lon_offset\n",
    "    \n",
    "    nearby_zips_with_distance = []\n",
    "    \n",
    "    # Add the target zip first\n",
    "    nearby_zips_with_distance.append((target_zip, 0))\n",
    "    \n",
    "    # Only check California zip codes within bounding box\n",
    "    for zip_obj in zipcodes.list_all():\n",
    "        zip_code = zip_obj['zip_code']\n",
    "        \n",
    "        # Skip the target zip since we already added it\n",
    "        if zip_code == target_zip:\n",
    "            continue\n",
    "            \n",
    "        # Only include California zip codes\n",
    "        if zip_obj['state'] != 'CA':\n",
    "            continue\n",
    "        \n",
    "        lat = float(zip_obj['lat'])\n",
    "        lon = float(zip_obj['long'])\n",
    "        \n",
    "        # Quick bounding box check first\n",
    "        if lat < min_lat or lat > max_lat or lon < min_lon or lon > max_lon:\n",
    "            continue\n",
    "        \n",
    "        # Only calculate exact distance for candidates in bounding box\n",
    "        coords = (lat, lon)\n",
    "        distance = geodesic(target_coords, coords).miles\n",
    "        \n",
    "        if distance <= radius_miles:\n",
    "            nearby_zips_with_distance.append((zip_code, distance))\n",
    "    \n",
    "    # Sort by distance (nearest to farthest)\n",
    "    nearby_zips_with_distance.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Debug output if requested\n",
    "    if debug:\n",
    "        print(f\"\\nZip codes within {radius_miles} miles of {target_zip}:\")\n",
    "        for zip_code, distance in nearby_zips_with_distance[:20]:\n",
    "            print(f\"  {zip_code}: {distance:.2f} miles\")\n",
    "    \n",
    "    # Return just the zip codes\n",
    "    return [zip_code for zip_code, distance in nearby_zips_with_distance]\n",
    "\n",
    "def scrape_json_url(url):\n",
    "    \"\"\"Fetch JSON from a given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def filter_providers_by_zip(url, target_zips):\n",
    "    \"\"\"\n",
    "    Fetch providers from Anthem JSON URL and return filtered provider data\n",
    "    for a list of ZIP codes (\"addresses\" -> \"zip\").\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to fetch provider data from\n",
    "        target_zips: A string (single ZIP) or list of strings (multiple ZIPs)\n",
    "    \n",
    "    Returns:\n",
    "        List of provider dictionaries matching the target ZIPs\n",
    "    \"\"\"\n",
    "    data = scrape_json_url(url)\n",
    "    if not data:\n",
    "        return []\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        print(\"Unexpected JSON structure.\")\n",
    "        return []\n",
    "\n",
    "    # Convert target_zips to list if it's a string\n",
    "    if isinstance(target_zips, str):\n",
    "        target_zips = [target_zips]\n",
    "    \n",
    "    # Normalize all target zips\n",
    "    target_zips = [str(z).strip() for z in target_zips]\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for p in data:\n",
    "        addresses = p.get(\"addresses\", [])\n",
    "        if not addresses:\n",
    "            continue\n",
    "\n",
    "        # Some providers may have multiple addresses\n",
    "        for addr in addresses:\n",
    "            zip_code = str(addr.get(\"zip\", \"\")).strip()\n",
    "            if zip_code in target_zips:\n",
    "                name_info = p.get(\"name\", {})\n",
    "                # Flatten name dict if present\n",
    "                full_name = \" \".join(\n",
    "                    filter(None, [name_info.get(\"first\"), name_info.get(\"middle\"), name_info.get(\"last\")])\n",
    "                ).strip()\n",
    "\n",
    "                # Specialty is a list — join into string\n",
    "                specialty = \", \".join(p.get(\"specialty\", [])) if isinstance(p.get(\"specialty\"), list) else p.get(\"specialty\")\n",
    "\n",
    "                result = {\n",
    "                    \"npi\": p.get(\"npi\"),\n",
    "                    \"type\": p.get(\"type\"),\n",
    "                    \"name\": full_name or p.get(\"name\"),\n",
    "                    \"address\": addr.get(\"address\"),\n",
    "                    \"city\": addr.get(\"city\"),\n",
    "                    \"state\": addr.get(\"state\"),\n",
    "                    \"zip\": zip_code,\n",
    "                    \"phone\": addr.get(\"phone\"),\n",
    "                    \"specialty\": specialty\n",
    "                }\n",
    "                filtered.append(result)\n",
    "                break  # Stop after first matching address for this provider\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    target_zips = get_zip_codes_within_distance('95008', 10, debug=True)\n",
    "    print(f\"\\nTotal: {len(target_zips)} zip codes found\\n\")\n",
    "    \n",
    "    json_url = \"https://www22.anthem.com/CMS/PROVIDERS_CAM.json\"\n",
    "    results = filter_providers_by_zip(json_url, target_zips)\n",
    "\n",
    "    print(f\"Found {len(results)} providers in the target ZIP codes.\\n\")\n",
    "    for r in results[:10]:\n",
    "        print(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Vector store with Chroma and embeddings\n",
    "We chunk scraped text and store embeddings locally. This will power retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root set to: /Users/ashli/langchain-for-good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/vlkns4y160x19_vsx97nhpz80000gn/T/ipykernel_12484/3163308097.py:38: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB ready. Docs: 14\n"
     ]
    }
   ],
   "source": [
    "# Build vector store\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the project root directory\n",
    "try:\n",
    "    # This works when running as a .py script\n",
    "    project_root = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    # This is a fallback for interactive environments (like Jupyter)\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "print(f\"Project root set to: {project_root}\")\n",
    "\n",
    "# Now you can define chroma_dir without an error\n",
    "chroma_dir = str(project_root / \"chroma_db\")\n",
    "\n",
    "# ... rest of your ChromaDB code\n",
    "# vectorstore = Chroma.from_documents(...)\n",
    "\n",
    "raw_docs = [\n",
    "    {\"source\": WHO_URL, \"text\": who_text},\n",
    "    {\"source\": CDC_URL, \"text\": cdc_text},\n",
    "]\n",
    "\n",
    "# Basic cleaning and chunking\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "\n",
    "documents = []\n",
    "for d in raw_docs:\n",
    "    if not d[\"text\"].startswith(\"ERROR\"):\n",
    "        for chunk in splitter.split_text(d[\"text\"]):\n",
    "            documents.append({\"page_content\": chunk, \"metadata\": {\"source\": d[\"source\"]}})\n",
    "\n",
    "# Embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create Chroma DB in a local folder\n",
    "chroma_dir = str(project_root / \"chroma_db\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=[\n",
    "        type(\"Doc\", (), doc)() for doc in documents  # lightweight doc-like objects\n",
    "    ],\n",
    "    embedding=embeddings,\n",
    "    persist_directory=chroma_dir,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "print(\"Vector DB ready. Docs:\", len(documents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) LangChain retrieval stage\n",
    "We use the retriever to ground the response. This is still LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/vlkns4y160x19_vsx97nhpz80000gn/T/ipykernel_12484/997239352.py:13: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "# LangChain retrieval\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain.llms import HuggingFaceHub\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face token\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Use a model from Hugging Face Hub\n",
    "llm = HuggingFaceHub(\n",
    "    #repo_id=\"dousery/medical-reasoning-gpt-oss-20b\", # Medical Reasoning GPT-OSS 20B - Strong medical knowledge\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\", # Mistral 7B - Excellent for Reasoning, balance of performance and efficiency\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7, \n",
    "        \"max_length\": 512,  # Increased for better responses\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.1\n",
    "    }\n",
    ")\n",
    "\n",
    "RAG_TEMPLATE = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {system}\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Conversation state:\n",
    "    - Symptoms: {symptom_state}\n",
    "    \n",
    "    User: {user_input}\n",
    "    Assistant: Provide an empathetic, educational reply. Do not diagnose or prescribe.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    RAG_TEMPLATE\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Helper to run a retrieved response\n",
    "def retrieved_response(user_input: str, symptom_state: str = \"\"):\n",
    "    docs = retriever.get_relevant_documents(user_input)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "    return chain.invoke({\n",
    "        \"system\": SYSTEM_PROMPT,\n",
    "        \"context\": context,\n",
    "        \"symptom_state\": symptom_state,\n",
    "        \"user_input\": user_input,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Leishmaniasis\n",
      "Leprosy (Hansen disease)\n",
      "Lymphatic filariasis (Elephantiasis)\n",
      "Malaria\n",
      "Malnutrition\n",
      "Marburg virus disease\n",
      "Maternal health\n",
      "Measles\n",
      "Medical devices\n",
      "Medicines\n",
      "Meningitis\n",
      "Mental health\n",
      "Micronutrients\n",
      "Middle East respiratory syndrome coronavirus (MERS-CoV)\n",
      "Mpox\n",
      "Mycetoma, chromoblastomycosis and other deep mycoses\n",
      "Neglected tropical diseases\n",
      "Newborn health\n",
      "Nipah virus infection\n",
      "Noncommunicable diseases\n",
      "Nursing and midwifery\n",
      "Nutrition\n",
      "Obesity\n",
      "Occupational health\n",
      "Onchocerciasis (river blindness)\n",
      "One Health\n",
      "Oral health\n",
      "Oxygen\n",
      "Palliative care\n",
      "Patient safety\n",
      "Pertussis\n",
      "Physical activity\n",
      "Plague\n",
      "Pneumonia\n",
      "Poliomyelitis (polio)\n",
      "Primary health care\n",
      "Quality of care\n",
      "Rabies\n",
      "Radiation\n",
      "Radiation emergencies\n",
      "Radon\n",
      "Refugee and migrant health\n",
      "Rehabilitation\n",
      "Research\n",
      "Respiratory syncytial virus\n",
      "{'source': 'https://www.who.int/health-topics'}\n",
      "\n",
      "Result 2:\n",
      "Leishmaniasis\n",
      "Leprosy (Hansen disease)\n",
      "Lymphatic filariasis (Elephantiasis)\n",
      "Malaria\n",
      "Malnutrition\n",
      "Marburg virus disease\n",
      "Maternal health\n",
      "Measles\n",
      "Medical devices\n",
      "Medicines\n",
      "Meningitis\n",
      "Mental health\n",
      "Micronutrients\n",
      "Middle East respiratory syndrome coronavirus (MERS-CoV)\n",
      "Mpox\n",
      "Mycetoma, chromoblastomycosis and other deep mycoses\n",
      "Neglected tropical diseases\n",
      "Newborn health\n",
      "Nipah virus infection\n",
      "Noncommunicable diseases\n",
      "Nursing and midwifery\n",
      "Nutrition\n",
      "Obesity\n",
      "Occupational health\n",
      "Onchocerciasis (river blindness)\n",
      "One Health\n",
      "Oral health\n",
      "Oxygen\n",
      "Palliative care\n",
      "Patient safety\n",
      "Pertussis\n",
      "Physical activity\n",
      "Plague\n",
      "Pneumonia\n",
      "Poliomyelitis (polio)\n",
      "Primary health care\n",
      "Quality of care\n",
      "Rabies\n",
      "Radiation\n",
      "Radiation emergencies\n",
      "Radon\n",
      "Refugee and migrant health\n",
      "Rehabilitation\n",
      "Research\n",
      "Respiratory syncytial virus\n",
      "{'source': 'https://www.who.int/health-topics'}\n",
      "\n",
      "Result 3:\n",
      "Leishmaniasis\n",
      "Leprosy (Hansen disease)\n",
      "Lymphatic filariasis (Elephantiasis)\n",
      "Malaria\n",
      "Malnutrition\n",
      "Marburg virus disease\n",
      "Maternal health\n",
      "Measles\n",
      "Medical devices\n",
      "Medicines\n",
      "Meningitis\n",
      "Mental health\n",
      "Micronutrients\n",
      "Middle East respiratory syndrome coronavirus (MERS-CoV)\n",
      "Mpox\n",
      "Mycetoma, chromoblastomycosis and other deep mycoses\n",
      "Neglected tropical diseases\n",
      "Newborn health\n",
      "Nipah virus infection\n",
      "Noncommunicable diseases\n",
      "Nursing and midwifery\n",
      "Nutrition\n",
      "Obesity\n",
      "Occupational health\n",
      "Onchocerciasis (river blindness)\n",
      "One Health\n",
      "Oral health\n",
      "Oxygen\n",
      "Palliative care\n",
      "Patient safety\n",
      "Pertussis\n",
      "Physical activity\n",
      "Plague\n",
      "Pneumonia\n",
      "Poliomyelitis (polio)\n",
      "Primary health care\n",
      "Quality of care\n",
      "Rabies\n",
      "Radiation\n",
      "Radiation emergencies\n",
      "Radon\n",
      "Refugee and migrant health\n",
      "Rehabilitation\n",
      "Research\n",
      "Respiratory syncytial virus\n",
      "{'source': 'https://www.who.int/health-topics'}\n"
     ]
    }
   ],
   "source": [
    "# Simple query example\n",
    "query = \"What is an MRI?\"\n",
    "results = vectorstore.similarity_search(query, k=3)  # retrieve top 3 matches\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain retrieval chain ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) SWITCH: LangChain → LangGraph\n",
    "We now orchestrate the multi-turn dialogue using LangGraph nodes and edges. Vector DB is used inside the retrieval node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generation error: 404 Client Error: Not Found for url: https://api-inference.huggingface.co/models/Qwen/Qwen3%E2%80%914B%E2%80%91Instruct%E2%80%912507 (Request ID: Root=1-68f9566d-6f7b09e81660e614175e9284;fe449af1-2af7-45be-9ec0-00bca8ff8670))\n",
      "\n",
      "Relevant info:\n",
      "MRI (Magnetic Resonance Imaging) uses strong magnetic fields and radio waves to create detailed images of organs and tissues.\n",
      "\n",
      "Contrast-enhanced MRI can help visualize inflammation, tumors, or vascular structures.\n"
     ]
    }
   ],
   "source": [
    "# LangGraph workflow\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\", \"\")\n",
    "\n",
    "client = InferenceClient(\n",
    "    token=HF_TOKEN or None,\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_input: str\n",
    "    symptom_state: str\n",
    "    retrieved_context: str\n",
    "    risk_level: str\n",
    "    response_text: str\n",
    "    empathy: bool\n",
    "\n",
    "DOCS: List[str] = [\n",
    "    \"MRI (Magnetic Resonance Imaging) uses strong magnetic fields and radio waves to create detailed images of organs and tissues.\",\n",
    "    \"Common MRI contraindications include some implanted devices; always screen patients for metal objects.\",\n",
    "    \"Contrast-enhanced MRI can help visualize inflammation, tumors, or vascular structures.\"\n",
    "]\n",
    "class MiniDoc:\n",
    "    def __init__(self, page_content): self.page_content = page_content\n",
    "\n",
    "def simple_retriever(query: str, k: int = 2) -> List[MiniDoc]:\n",
    "    q = (query or \"\").lower()\n",
    "    scored = []\n",
    "    for d in DOCS:\n",
    "        score = sum(int(word in d.lower()) for word in q.split())\n",
    "        scored.append((score, d))\n",
    "    scored.sort(reverse=True)\n",
    "    return [MiniDoc(d) for _, d in scored[:k]]\n",
    "\n",
    "def retrieved_response(user_input: str, symptom_state: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a compassionate medical assistant. Be concise and clear.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_input}\\nSymptoms: {symptom_state}\"},\n",
    "    ]\n",
    "    # Try chat completion first (HF router-compatible)\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            # Choose a chat-capable id that works with the router.\n",
    "            # You can swap to any supported chat model; examples in docs.\n",
    "            model=\"Qwen/Qwen3‑4B‑Instruct‑2507\",  # routed via HF providers\n",
    "            messages=messages,\n",
    "            max_tokens=500,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return completion.choices[0].message[\"content\"]\n",
    "    except Exception:\n",
    "        # Fallback to plain text generation against a Hub model\n",
    "        prompt = (\n",
    "            \"You are a compassionate medical assistant.\\n\\n\"\n",
    "            f\"User question: {user_input}\\n\"\n",
    "            f\"Symptoms: {symptom_state}\\n\\n\"\n",
    "            \"Answer clearly and kindly:\"\n",
    "        )\n",
    "        try:\n",
    "            text = client.text_generation(\n",
    "                prompt,\n",
    "                model=\"Qwen/Qwen3‑4B‑Instruct‑2507\",\n",
    "                max_new_tokens=500,\n",
    "                temperature=0.2,\n",
    "                return_full_text=False,\n",
    "            )\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"(Generation error: {e})\"\n",
    "\n",
    "def node_empathy(state: State) -> State:\n",
    "    return {**state, \"empathy\": True}\n",
    "\n",
    "def node_collect_symptoms(state: State) -> State:\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    known = state.get(\"symptom_state\", \"\")\n",
    "    new_symptom_state = (known + \" \" + user_input).strip()\n",
    "    return {**state, \"symptom_state\": new_symptom_state}\n",
    "\n",
    "def node_retrieve(state: State) -> State:\n",
    "    query = state.get(\"user_input\", \"\")\n",
    "    docs = simple_retriever(query)\n",
    "    retrieved_context = \"\\n\\n\".join(d.page_content for d in docs) if docs else \"\"\n",
    "    return {**state, \"retrieved_context\": retrieved_context}\n",
    "\n",
    "def node_risk_assess(state: State) -> State:\n",
    "    text = f\"{state.get('symptom_state','')} {state.get('user_input','')}\".lower()\n",
    "    red_flags = [\"chest pain\", \"shortness of breath\", \"fainting\", \"severe headache\", \"weakness on one side\"]\n",
    "    risk = \"high\" if any(k in text for k in red_flags) else \"low\"\n",
    "    return {**state, \"risk_level\": risk}\n",
    "\n",
    "def node_respond(state: State) -> State:\n",
    "    base = retrieved_response(\n",
    "        user_input=state.get(\"user_input\", \"\"),\n",
    "        symptom_state=state.get(\"symptom_state\", \"\"),\n",
    "    )\n",
    "    ctx = state.get(\"retrieved_context\", \"\")\n",
    "    risk = state.get(\"risk_level\", \"low\")\n",
    "    # Light post-processing to include retrieved context + safety nudge\n",
    "    extra = f\"\\n\\nRelevant info:\\n{ctx}\" if ctx else \"\"\n",
    "    safety = \"\\n\\nIf you have severe or worsening symptoms, seek urgent care.\" if risk == \"high\" else \"\"\n",
    "    return {**state, \"response_text\": base + extra + safety}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"empathy_node\", node_empathy)\n",
    "builder.add_node(\"collect_symptoms\", node_collect_symptoms)\n",
    "builder.add_node(\"retrieve\", node_retrieve)\n",
    "builder.add_node(\"risk\", node_risk_assess)\n",
    "builder.add_node(\"respond\", node_respond)\n",
    "\n",
    "builder.set_entry_point(\"empathy_node\")\n",
    "builder.add_edge(\"empathy_node\", \"collect_symptoms\")\n",
    "builder.add_edge(\"collect_symptoms\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"risk\")\n",
    "builder.add_edge(\"risk\", \"respond\")\n",
    "builder.add_edge(\"respond\", END)\n",
    "\n",
    "app = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "result = app.invoke(\n",
    "    {\"user_input\": \"what is an MRI\", \"symptom_state\": \"\"},\n",
    "    config={\"configurable\": {\"thread_id\": \"main\"}},\n",
    ")\n",
    "# print(result.choices[0].message[\"content\"])\n",
    "print(result[\"response_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Disclaimer filter and sentiment analysis\n",
    "We add a toggle to include the disclaimer and run a lightweight VADER sentiment to adapt tone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disclaimer + sentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def apply_disclaimer(text: str, enabled: bool) -> str:\n",
    "    if not enabled:\n",
    "        return text\n",
    "    if DISCLAIMER_TEXT in text:\n",
    "        return text\n",
    "    return f\"{DISCLAIMER_TEXT}\\n\\n{text}\"\n",
    "\n",
    "\n",
    "def adapt_tone_with_sentiment(user_input: str, reply: str) -> str:\n",
    "    scores = analyzer.polarity_scores(user_input)\n",
    "    if scores.get(\"neg\", 0) > 0.4:\n",
    "        # append a brief empathetic line\n",
    "        return reply + \"\\n\\nI’m here with you. That sounds tough.\"\n",
    "    return reply\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer and sentiment ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Gradio UI for Health Navigator\n",
    "Interactive chat interface with disclaimer toggle and conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puOmAtTdhSbR"
   },
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Global conversation state\n",
    "conversation_history = []\n",
    "\n",
    "def chat_with_agent(message: str, history: List[Tuple[str, str]], disclaimer_enabled: bool) -> Tuple[str, List[Tuple[str, str]]]:\n",
    "    \"\"\"Main chat function that processes user input through the LangGraph workflow\"\"\"\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    try:\n",
    "        # Run through LangGraph workflow\n",
    "        config = {\"configurable\": {\"thread_id\": \"main\"}}\n",
    "        result = app.invoke(\n",
    "            {\"user_input\": message, \"symptom_state\": \"\"}, \n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # Get the response\n",
    "        response = result.get(\"response_text\", \"I'm sorry, I couldn't process that.\")\n",
    "        \n",
    "        # Apply sentiment adaptation\n",
    "        response = adapt_tone_with_sentiment(message, response)\n",
    "        \n",
    "        # Apply disclaimer if enabled\n",
    "        response = apply_disclaimer(response, disclaimer_enabled)\n",
    "        \n",
    "        # Update history\n",
    "        history.append((message, response))\n",
    "        \n",
    "        return \"\", history\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"I encountered an error: {str(e)}. Please try again.\"\n",
    "        history.append((message, error_msg))\n",
    "        return \"\", history\n",
    "\n",
    "def clear_history():\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    return []\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Health Navigator Agent\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🏥 Health Navigator Agent\n",
    "    \n",
    "    A compassionate AI assistant that helps you understand health topics using WHO/CDC guidance.\n",
    "    \n",
    "    **⚠️ Important:** This is for educational purposes only and does not provide medical advice.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                value=[],\n",
    "                height=500,\n",
    "                label=\"Conversation\",\n",
    "                show_label=True\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg_input = gr.Textbox(\n",
    "                    placeholder=\"Describe your symptoms or ask a health question...\",\n",
    "                    label=\"Your message\",\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                send_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "            \n",
    "            with gr.Row():\n",
    "                disclaimer_toggle = gr.Checkbox(\n",
    "                    label=\"Include medical disclaimer\",\n",
    "                    value=True,\n",
    "                    info=\"Adds safety disclaimer to responses\"\n",
    "                )\n",
    "                clear_btn = gr.Button(\"Clear History\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Features\n",
    "            - 🤗 Empathetic responses\n",
    "            - 📚 WHO/CDC guidance retrieval\n",
    "            - 🧠 Multi-turn conversation\n",
    "            - ⚠️ Safety disclaimers\n",
    "            - 💭 Sentiment analysis\n",
    "            - 🔄 LangGraph workflow\n",
    "            \"\"\")\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ### How it works\n",
    "            1. **Empathy**: Acknowledges your feelings\n",
    "            2. **Symptom Collection**: Gathers information\n",
    "            3. **Retrieval**: Finds relevant guidance\n",
    "            4. **Risk Assessment**: Evaluates urgency\n",
    "            5. **Response**: Provides educational support\n",
    "            \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    send_btn.click(\n",
    "        chat_with_agent,\n",
    "        inputs=[msg_input, chatbot, disclaimer_toggle],\n",
    "        outputs=[msg_input, chatbot]\n",
    "    )\n",
    "    \n",
    "    msg_input.submit(\n",
    "        chat_with_agent,\n",
    "        inputs=[msg_input, chatbot, disclaimer_toggle],\n",
    "        outputs=[msg_input, chatbot]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        clear_history,\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "# This is the crucial part to start the application\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True) # debug=True provides more detailed error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Gradio UI ready! Run demo.launch() to start the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Launch and Test the Health Navigator\n",
    "Run the Gradio interface to test the complete experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Test Hugging Face Model Performance\n",
    "Let's test the model with a sample health question to verify performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model performance\n",
    "print(\"🧪 Testing Hugging Face model performance...\")\n",
    "\n",
    "# Test 1: Simple health question\n",
    "test_input = \"I have a headache and feel tired. What should I know?\"\n",
    "print(f\"\\n📝 Test Input: {test_input}\")\n",
    "\n",
    "try:\n",
    "    # Test the LangGraph workflow\n",
    "    config = {\"configurable\": {\"thread_id\": \"test\"}}\n",
    "    result = app.invoke({\"user_input\": test_input}, config=config)\n",
    "    \n",
    "    print(\"✅ LangGraph workflow completed successfully!\")\n",
    "    print(f\"📊 Risk Level: {result.get('risk_level', 'unknown')}\")\n",
    "    print(f\"💬 Response Length: {len(result.get('response_text', ''))} characters\")\n",
    "    print(f\"🔍 Retrieved Context Length: {len(result.get('retrieved_context', ''))} characters\")\n",
    "    \n",
    "    # Show a snippet of the response\n",
    "    response = result.get('response_text', '')\n",
    "    if response:\n",
    "        print(f\"\\n🤖 Model Response Preview:\")\n",
    "        print(response[:200] + \"...\" if len(response) > 200 else response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error testing model: {e}\")\n",
    "    print(\"This might be due to Hugging Face API limits or model availability.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting Health Navigator Agent...\")\n",
    "    print(\"📊 Vector DB contains\", len(documents), \"document chunks\")\n",
    "    print(\"🤖 Using Hugging Face model: Mistral-7B-Instruct\")\n",
    "    print(\"🔗 LangGraph workflow with\", len(app.get_graph().nodes), \"nodes\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Launching Gradio interface...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Launch with public sharing disabled for security\n",
    "    demo.launch(\n",
    "        share=False,  # Set to True if you want to share publicly\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7860,\n",
    "        show_error=True,\n",
    "        quiet=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Ready to Launch! 🚀\n",
    "\n",
    "The Health Navigator Agent is now complete with:\n",
    "\n",
    "✅ **Fixed Dependencies**: Using local `requirements.txt`  \n",
    "✅ **Centralized Prompts**: Scalable system and human prompts  \n",
    "✅ **Web Scraping**: WHO/CDC health guidance loaded  \n",
    "✅ **Vector Database**: Chroma with sentence-transformers embeddings  \n",
    "✅ **LangChain Retrieval**: RAG pipeline for context  \n",
    "✅ **LangGraph Workflow**: Multi-turn dialogue orchestration  \n",
    "✅ **Disclaimer Filter**: Toggle for safety disclaimers  \n",
    "✅ **Sentiment Analysis**: VADER for emotional adaptation  \n",
    "✅ **Gradio UI**: Interactive chat interface  \n",
    "\n",
    "**To run the agent:**\n",
    "1. Execute all cells above\n",
    "2. Run the test cell to verify model performance\n",
    "3. Launch the Gradio interface\n",
    "\n",
    "**Note**: The Hugging Face model (Mistral-7B-Instruct) provides good performance for health conversations. If you encounter API limits, consider using OpenAI or other providers by updating the model configuration in the LangChain retrieval cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
